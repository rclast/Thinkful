{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My challenge for this assignment is to evaluate the classifier I had created in a previous assignment and to try to make 5 versions of it as I try to make it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to reload the code for the model that I had made previously in order to then evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('yelp_labelled.txt', delimiter = \"\\t\", names=['Comment', 'Sentiment'])\n",
    "\n",
    "keywords = [\"not\", \"bad\", \"didn't\", \"worst\", \"poor\", \"slow\"]\n",
    "\n",
    "for key in keywords:\n",
    "    df[str(key)] = df.Comment.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )\n",
    "       \n",
    "data = df[keywords]\n",
    "target = df['Sentiment']\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now run a confusion matrix to assess what type of errors are occuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119, 381],\n",
       "       [ 21, 479]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(target, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My model was very good at identifying the positive reviews, hitting at 479 out of 500, or a 95.8% rate. However, my model did not identify negative well, hitting at 119 out of 500, or a 23.8% rate. I therefore have high sensitivity, identifying the positive well, but low specificity because of how often I falsely identified negatives as positive. This sample has an equal number of class type, with 500 negative reviews and 500 positive reviews, so the failure is not related to class imbalance.\n",
    "\n",
    "I will run a holdout group evaluation and then a cross validation to see if those evaluations give me different results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.585\n",
      "Testing on Sample: 0.598\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65, 0.58, 0.61, 0.52, 0.61, 0.62, 0.63, 0.62, 0.56, 0.58])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the holdout group evaluation it was essentially the same, so there are now red flags there. In the cross validation, the scores are all around the 59% mark that I have hit.\n",
    "\n",
    "My goal now is to find better features that can help my model distinguish when a review is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv('yelp_labelled.txt', delimiter = \"\\t\", names=['Comment', 'Sentiment'])\n",
    "# I will keep the keywords from the first version, and try adding more\n",
    "keywords_2 = [\"not\", \"bad\", \"didn't\", \"worst\", \"poor\", \"slow\", \"disappointed\",\n",
    "            \"gross\", \"bland\", \"stinks\", \"wrong\", \"flavorless\", \"stay away\"]\n",
    "\n",
    "for key in keywords_2:\n",
    "    df_2[str(key)] = df_2.Comment.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )\n",
    "       \n",
    "data_2 = df_2[keywords_2]\n",
    "target_2 = df_2['Sentiment']\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb_2 = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data\n",
    "bnb_2.fit(data_2, target_2)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred_2 = bnb_2.predict(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[134, 366],\n",
       "       [ 21, 479]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(target_2, y_pred_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disappointingly, I got a similar result. My sensitivity is exactly the same at 95.8%. My specificity had a slight increase from 23.8% to 26.8%, classifying only 15 more negatives correctly. I will need to come up with either more keywords or a different approach.\n",
    "\n",
    "I will try TF-IDF feature extraction. I will first see what features I can extract from the positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food delicious', 'food good', 'food great', 'food service', 'friendly staff', 'good food', 'good prices', 'good service', 'great food', 'great place', 'great service', 'really good', 'service good']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df_3 = pd.read_csv('yelp_labelled.txt', delimiter = \"\\t\", names=['Comment', 'Sentiment'])\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=13, ngram_range=(2,3))\n",
    "X = vectorizer.fit_transform(df_3[df_3['Sentiment'] == 1]['Comment'])\n",
    "keywords_3 = vectorizer.get_feature_names()\n",
    "\n",
    "print(keywords_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keywords_3:\n",
    "    df_3[str(key)] = df_3.Comment.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )\n",
    "       \n",
    "data_3 = df_3[keywords_3]\n",
    "target_3 = df_3['Sentiment']\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb_3 = BernoulliNB()\n",
    "\n",
    "bnb_3.fit(data_3, target_3)\n",
    "\n",
    "y_pred_3 = bnb_3.predict(data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[500,   0],\n",
       "       [492,   8]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(target_3, y_pred_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this essentially called everything positive. Which is great for my problem of specificity, but threw my sensitivity out the window. I will have to try to add more features from positive and I will add features from the negative reviews as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food delicious', 'food good', 'food great', 'food service', 'friendly staff', 'good food', 'good prices', 'good service', 'great food', 'great place', 'great service', 'love place', 'pretty good', 'really good', 'second time', 'service food', 'service good', 'super friendly', 'vegas buffet', 'won disappointed']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df_4 = pd.read_csv('yelp_labelled.txt', delimiter = \"\\t\", names=['Comment', 'Sentiment'])\n",
    "\n",
    "vectorizer_4 = TfidfVectorizer(stop_words='english', max_features=20, ngram_range=(2,3))\n",
    "X_4_pos = vectorizer_4.fit_transform(df_4[df_4['Sentiment'] == 1]['Comment'])\n",
    "keywords_4_pos = vectorizer_4.get_feature_names()\n",
    "\n",
    "print(keywords_4_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10 minutes', '20 minutes', '30 minutes', 'anytime soon', 'bad food', 'customer service', 'don know', 'don think', 'feel like', 'going anytime', 'going anytime soon', 'good food', 'good way', 'mediocre food', 'minutes food', 'service slow', 'think ll', 'waste time', 'won going', 'zero stars']\n"
     ]
    }
   ],
   "source": [
    "#Now add negative features\n",
    "vectorizer_4 = TfidfVectorizer(stop_words='english', max_features=20, ngram_range=(2,3))\n",
    "X_4_neg = vectorizer_4.fit_transform(df_4[df_4['Sentiment'] == 0]['Comment'])\n",
    "keywords_4_neg = vectorizer_4.get_feature_names()\n",
    "\n",
    "print(keywords_4_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keywords_4_pos:\n",
    "    df_4[str(key)] = df_4.Comment.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )\n",
    "\n",
    "for key in keywords_4_neg:\n",
    "    df_4[str(key)] = df_4.Comment.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )\n",
    "              \n",
    "data_4 = df_4[keywords_4_pos] & df_4[keywords_4_neg]\n",
    "target_4 = df_4['Sentiment']\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb_4 = BernoulliNB()\n",
    "\n",
    "bnb_4.fit(data_4, target_4)\n",
    "\n",
    "y_pred_4 = bnb_4.predict(data_4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2, 498],\n",
       "       [  1, 499]], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(target_4, y_pred_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am surprised at this development. My model is now calling virtually everything negative. This is the reverse of the problem I had with the previous iteration using tf-idf. For my fifth and final iteration, I will try to find a balance of the two by having less. Perhaps I added too many. I will return to 13 features for positive like my original, and only have 10 features for negative. Hopefully this will balance it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['food delicious', 'food good', 'food great', 'food service', 'friendly staff', 'good food', 'good prices', 'good service', 'great food', 'great place', 'great service', 'really good', 'service good']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df_5 = pd.read_csv('yelp_labelled.txt', delimiter = \"\\t\", names=['Comment', 'Sentiment'])\n",
    "\n",
    "vectorizer_5 = TfidfVectorizer(stop_words='english', max_features=13, ngram_range=(2,3))\n",
    "X_5_pos = vectorizer_5.fit_transform(df_5[df_5['Sentiment'] == 1]['Comment'])\n",
    "keywords_5_pos = vectorizer_5.get_feature_names()\n",
    "\n",
    "print(keywords_5_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10 minutes', 'anytime soon', 'bad food', 'customer service', 'don think', 'going anytime', 'service slow', 'waste time', 'won going', 'zero stars']\n"
     ]
    }
   ],
   "source": [
    "#Now add negative features\n",
    "vectorizer_5 = TfidfVectorizer(stop_words='english', max_features=10, ngram_range=(2,3))\n",
    "X_5_neg = vectorizer_5.fit_transform(df_5[df_5['Sentiment'] == 0]['Comment'])\n",
    "keywords_5_neg = vectorizer_5.get_feature_names()\n",
    "\n",
    "print(keywords_5_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keywords_5_pos:\n",
    "    df_5[str(key)] = df_5.Comment.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )\n",
    "\n",
    "for key in keywords_5_neg:\n",
    "    df_5[str(key)] = df_5.Comment.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )\n",
    "              \n",
    "data_5 = df_5[keywords_5_pos] & df_5[keywords_5_neg]\n",
    "target_5 = df_5['Sentiment']\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb_5 = BernoulliNB()\n",
    "\n",
    "bnb_5.fit(data_5, target_5)\n",
    "\n",
    "y_pred_5 = bnb_5.predict(data_5)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[500,   0],\n",
       "       [500,   0]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(target_5, y_pred_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just like that, I am back to the same problem. I have come to another point of needing to learn more I believe. My experiment with tf-idf didn't turn out the way I wanted. But I believe that I will be learning more in depth about how to use it later in the course. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
