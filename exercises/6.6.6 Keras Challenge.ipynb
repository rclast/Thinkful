{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will showcase my ability to use Keras and Tensorflow to create neural networks by working with the Fashion-MNIST data by Zalando https://www.kaggle.com/zalando-research/fashionmnist.\n",
    "\n",
    "The data has ten labels for 60,000 training images and 10,000 test images-\n",
    "- 0 T-shirt/top\n",
    "- 1 Trouser\n",
    "- 2 Pullover\n",
    "- 3 Dress\n",
    "- 4 Coat\n",
    "- 5 Sandal\n",
    "- 6 Shirt\n",
    "- 7 Sneaker\n",
    "- 8 Bag\n",
    "- 9 Ankle boot \n",
    "\n",
    "The goal of this challenge is to make 5 different iterations of a neural network, compare them for accuracy, and decide which I would move forward with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import various componenets for model building\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers import LSTM, Input, TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Import the backend\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('fashion-mnist_train.csv')\n",
    "test = pd.read_csv('fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['label']\n",
    "x_train = train.drop(columns='label')\n",
    "del train\n",
    "\n",
    "y_test = test['label']\n",
    "x_test = test.drop(columns='label')\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Convert to float32 for type consistency\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize values to 1 from 0 to 255 (256 values of pixels)\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Print sample sizes\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "# So instead of one column with 10 values, create 10 binary columns\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1\n",
    "A Multi-Layer Perceptron network with two fully connected layers with 64 perceptrons each and 10% dropouts after each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ross Last\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Ross Last\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(Dense(64, activation='relu', input_shape=(784,)))\n",
    "model_1.add(Dropout(0.1))\n",
    "model_1.add(Dense(64, activation='relu'))\n",
    "model_1.add(Dropout(0.1))\n",
    "model_1.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model_1.summary()\n",
    "\n",
    "# Compile the model to put it all together.\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.3056 - acc: 0.8873 - val_loss: 0.3257 - val_acc: 0.8809\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.2978 - acc: 0.8903 - val_loss: 0.3232 - val_acc: 0.8840\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2969 - acc: 0.8908 - val_loss: 0.3166 - val_acc: 0.8876\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2914 - acc: 0.8931 - val_loss: 0.3165 - val_acc: 0.8846\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2859 - acc: 0.8960 - val_loss: 0.3113 - val_acc: 0.8874\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2826 - acc: 0.8949 - val_loss: 0.3349 - val_acc: 0.8834\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2784 - acc: 0.8974 - val_loss: 0.3143 - val_acc: 0.8877\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2781 - acc: 0.8973 - val_loss: 0.3334 - val_acc: 0.8784\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.2738 - acc: 0.9001 - val_loss: 0.3180 - val_acc: 0.8868\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.2700 - acc: 0.9015 - val_loss: 0.3231 - val_acc: 0.8835\n",
      "Test loss: 0.32312642331123353\n",
      "Test accuracy: 0.8835\n"
     ]
    }
   ],
   "source": [
    "history_1 = model_1.fit(x_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score_1 = model_1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score_1[0])\n",
    "print('Test accuracy:', score_1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2\n",
    "Same as model 1, but double the number of perceptrons in the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Dense(128, activation='relu', input_shape=(784,)))\n",
    "model_2.add(Dropout(0.1))\n",
    "model_2.add(Dense(64, activation='relu'))\n",
    "model_2.add(Dropout(0.1))\n",
    "model_2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model_2.summary()\n",
    "\n",
    "# Compile the model to put it all together.\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2818 - acc: 0.8967 - val_loss: 0.3060 - val_acc: 0.8907\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2739 - acc: 0.8998 - val_loss: 0.3690 - val_acc: 0.8693\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2714 - acc: 0.9004 - val_loss: 0.3026 - val_acc: 0.8938\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2645 - acc: 0.9029 - val_loss: 0.3033 - val_acc: 0.8933\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2602 - acc: 0.9039 - val_loss: 0.3252 - val_acc: 0.8897\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2560 - acc: 0.9053 - val_loss: 0.3080 - val_acc: 0.8972\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2509 - acc: 0.9072 - val_loss: 0.3253 - val_acc: 0.8878\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2491 - acc: 0.9082 - val_loss: 0.3149 - val_acc: 0.8930\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2457 - acc: 0.9101 - val_loss: 0.3287 - val_acc: 0.8927\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2409 - acc: 0.9109 - val_loss: 0.3493 - val_acc: 0.8831\n",
      "Test loss: 0.34928876698613165\n",
      "Test accuracy: 0.8831\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(x_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score_2 = model_2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score_2[0])\n",
    "print('Test accuracy:', score_2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3\n",
    "I will add a third layer and make all layers have 128 perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 134,794\n",
      "Trainable params: 134,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "\n",
    "model_3.add(Dense(128, activation='relu', input_shape=(784,)))\n",
    "model_3.add(Dropout(0.1))\n",
    "model_3.add(Dense(128, activation='relu'))\n",
    "model_3.add(Dropout(0.1))\n",
    "model_3.add(Dense(128, activation='relu'))\n",
    "model_3.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model_3.summary()\n",
    "\n",
    "# Compile the model to put it all together.\n",
    "model_3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2755 - acc: 0.8990 - val_loss: 0.3054 - val_acc: 0.8883\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2713 - acc: 0.8994 - val_loss: 0.2975 - val_acc: 0.8956\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2655 - acc: 0.9018 - val_loss: 0.2934 - val_acc: 0.8970\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2612 - acc: 0.9035 - val_loss: 0.3134 - val_acc: 0.8871\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2578 - acc: 0.9041 - val_loss: 0.3261 - val_acc: 0.8889\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2535 - acc: 0.9054 - val_loss: 0.3108 - val_acc: 0.8930\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2492 - acc: 0.9082 - val_loss: 0.2998 - val_acc: 0.8940\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2454 - acc: 0.9094 - val_loss: 0.3097 - val_acc: 0.8972\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.2444 - acc: 0.9090 - val_loss: 0.3118 - val_acc: 0.8938\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2415 - acc: 0.9110 - val_loss: 0.3368 - val_acc: 0.8915\n",
      "Test loss: 0.3367961868703365\n",
      "Test accuracy: 0.8915\n"
     ]
    }
   ],
   "source": [
    "history_3 = model_3.fit(x_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score_3 = model_3.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score_3[0])\n",
    "print('Test accuracy:', score_3[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4\n",
    "I will try 5 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 167,818\n",
      "Trainable params: 167,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "\n",
    "model_4.add(Dense(128, activation='relu', input_shape=(784,)))\n",
    "model_4.add(Dropout(0.1))\n",
    "model_4.add(Dense(128, activation='relu'))\n",
    "model_4.add(Dropout(0.1))\n",
    "model_4.add(Dense(128, activation='relu'))\n",
    "model_4.add(Dropout(0.1))\n",
    "model_4.add(Dense(128, activation='relu'))\n",
    "model_4.add(Dropout(0.1))\n",
    "model_4.add(Dense(128, activation='relu'))\n",
    "model_4.add(Dropout(0.1))\n",
    "model_4.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model_4.summary()\n",
    "\n",
    "# Compile the model to put it all together.\n",
    "model_4.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.6468 - acc: 0.7614 - val_loss: 0.4574 - val_acc: 0.8329\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.4464 - acc: 0.8404 - val_loss: 0.3834 - val_acc: 0.8616\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.4000 - acc: 0.8564 - val_loss: 0.3658 - val_acc: 0.8701\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.3747 - acc: 0.8650 - val_loss: 0.4035 - val_acc: 0.8617\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.3570 - acc: 0.8732 - val_loss: 0.3521 - val_acc: 0.8718\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.3419 - acc: 0.8779 - val_loss: 0.3414 - val_acc: 0.8817\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.3317 - acc: 0.8817 - val_loss: 0.3316 - val_acc: 0.8779\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.3210 - acc: 0.8842 - val_loss: 0.3427 - val_acc: 0.8785\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.3167 - acc: 0.8860 - val_loss: 0.3513 - val_acc: 0.8752\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.3113 - acc: 0.8896 - val_loss: 0.3262 - val_acc: 0.8855\n",
      "Test loss: 0.32618091022968293\n",
      "Test accuracy: 0.8855\n"
     ]
    }
   ],
   "source": [
    "history_4 = model_4.fit(x_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score_4 = model_4.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score_4[0])\n",
    "print('Test accuracy:', score_4[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5\n",
    "I will add more perceptrons to each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 895,882\n",
      "Trainable params: 895,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5 = Sequential()\n",
    "\n",
    "model_5.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model_5.add(Dropout(0.1))\n",
    "model_5.add(Dense(512, activation='relu'))\n",
    "model_5.add(Dropout(0.1))\n",
    "model_5.add(Dense(256, activation='relu'))\n",
    "model_5.add(Dropout(0.1))\n",
    "model_5.add(Dense(256, activation='relu'))\n",
    "model_5.add(Dropout(0.1))\n",
    "model_5.add(Dense(128, activation='relu'))\n",
    "model_5.add(Dropout(0.1))\n",
    "model_5.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model_5.summary()\n",
    "\n",
    "# Compile the model to put it all together.\n",
    "model_5.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.6373 - acc: 0.7664 - val_loss: 0.5535 - val_acc: 0.8034\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.4363 - acc: 0.8426 - val_loss: 0.4227 - val_acc: 0.8484\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.3907 - acc: 0.8613 - val_loss: 0.3541 - val_acc: 0.8704\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.3696 - acc: 0.8698 - val_loss: 0.3941 - val_acc: 0.8681\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.3611 - acc: 0.8741 - val_loss: 0.3537 - val_acc: 0.8781\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.3571 - acc: 0.8781 - val_loss: 0.3420 - val_acc: 0.8850\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.3539 - acc: 0.8784 - val_loss: 0.3664 - val_acc: 0.8703\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.3522 - acc: 0.8806 - val_loss: 0.3666 - val_acc: 0.8662 0.3521 - acc: 0\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.3552 - acc: 0.8805 - val_loss: 0.3678 - val_acc: 0.8781\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.3557 - acc: 0.8829 - val_loss: 0.3842 - val_acc: 0.8859\n",
      "Test loss: 0.38422405586242675\n",
      "Test accuracy: 0.8859\n"
     ]
    }
   ],
   "source": [
    "history_5 = model_5.fit(x_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score_5 = model_5.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score_5[0])\n",
    "print('Test accuracy:', score_5[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision\n",
    "\n",
    "Model 3 had the highest accuray at 0.8915, so I would move forward with this model. It is interesting that 5 layers (Models 4 and 5) did not perform better, in fact were slightly worse, than model 3 with three layers. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
